<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://kings-ai-rg.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://kings-ai-rg.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-06-06T09:26:03+00:00</updated><id>https://kings-ai-rg.github.io/feed.xml</id><title type="html">Kings AI Reading Group</title><subtitle>Kings AI Reading Group </subtitle><entry><title type="html">On the Biology of a Large Language Model (Anthropic)</title><link href="https://kings-ai-rg.github.io/blog/2025/biology-llms-anthropic/" rel="alternate" type="text/html" title="On the Biology of a Large Language Model (Anthropic)"/><published>2025-04-11T12:00:00+00:00</published><updated>2025-04-11T12:00:00+00:00</updated><id>https://kings-ai-rg.github.io/blog/2025/biology-llms-anthropic</id><content type="html" xml:base="https://kings-ai-rg.github.io/blog/2025/biology-llms-anthropic/"><![CDATA[<p><strong><a href="https://www.linkedin.com/in/nathaliekirch/">Nathalie Kirch</a></strong> presented an overview of the recent Anthropic release: On the Biology of a Large Language Model <a class="citation" href="#lindsey2025biology">(Lindsey et al., 2025)</a>.</p> <p><strong><em>Abstract</em></strong></p> <p>In this talk, we explored the recent Anthropic Thread: On the Biology of a Large Language Model. It was a thought-provoking investigation into the internal structures, behaviors, and emergent properties of large language models (LLMs). The metaphor between biological systems and artificial intelligence was particularly strong and, this presentation explored how LLMs—like biological organisms—develop internal representations, organize “thought,” and respond adaptively to stimuli via a mechanistic perspective.</p>]]></content><author><name></name></author><category term="talks"/><category term="paper-presentation"/><summary type="html"><![CDATA[Presented by Nathalie Kirch]]></summary></entry><entry><title type="html">Reflections on International AI Safety Report</title><link href="https://kings-ai-rg.github.io/blog/2025/international-AI-safety-report/" rel="alternate" type="text/html" title="Reflections on International AI Safety Report"/><published>2025-03-07T12:00:00+00:00</published><updated>2025-03-07T12:00:00+00:00</updated><id>https://kings-ai-rg.github.io/blog/2025/international-AI-safety-report</id><content type="html" xml:base="https://kings-ai-rg.github.io/blog/2025/international-AI-safety-report/"><![CDATA[<p><strong><a href="https://www.linkedin.com/in/israelfmw/">Israel Mason-Williams</a></strong>, <strong><a href="https://www.linkedin.com/in/nathaliekirch/">Nathalie Kirch</a></strong> and <strong><a href="https://www.linkedin.com/in/archie-sage-3388bb260/">Archie Sage</a></strong> presented a summary of the International AI Safety Report <a class="citation" href="#bengio2025international">(Bengio et al., 2025)</a></p> <p><strong><em>Abstract</em></strong></p> <p>This series of talks presented key insights from the latest International Safety Report, a comprehensive analysis of the three sections comprising Capabilities of general-purpose AI, Risks, and Technical approaches to risk management. Drawing on data from government agencies, industry leaders, and international organizations, the report highlights critical opinions surrounding Safe AI development. Antendees gained a perspective on evolving safety standards, regulatory frameworks, and the role of technology and collaboration in mitigating risk.</p> <p><strong>Updates</strong></p> <p>The International Safety Report is an iterative document, the reflections of this talk may not represent future versions of this document.</p>]]></content><author><name></name></author><category term="talks"/><category term="meta-research"/><category term="governance"/><category term="policy"/><summary type="html"><![CDATA[Presented by Israel Mason-Williams,Nathalie Kirch and Archie Sage.]]></summary></entry><entry><title type="html">DeepSeek V1, V2 and V3 Deep Dive</title><link href="https://kings-ai-rg.github.io/blog/2025/DeepSeek/" rel="alternate" type="text/html" title="DeepSeek V1, V2 and V3 Deep Dive"/><published>2025-02-14T12:00:00+00:00</published><updated>2025-02-14T12:00:00+00:00</updated><id>https://kings-ai-rg.github.io/blog/2025/DeepSeek</id><content type="html" xml:base="https://kings-ai-rg.github.io/blog/2025/DeepSeek/"><![CDATA[<p><strong><a href="https://www.linkedin.com/in/avyav-kumar-singh/">Avyav Singh</a></strong> presented the collection of papers that led to the innovative appraoch adopted to create DeepSeek V1 and V2 (missing reference) (missing reference), (missing reference), (missing reference) and (missing reference)</p> <p><strong><em>Abstract</em></strong></p> <p>This talk explored the rapid evolution of DeepSeek’s foundational models from V1 through V3, highlighting key architectural advancements and capabilities. We explored in depth the key innovations which enabled the sucess of DeepSeek namely the introduced Mixture-of-Experts (MoE) architecture for scalable compute and dynamic routing, Multi-head Latent Attention and auxiliary-loss-free strategy for load balancing.</p>]]></content><author><name></name></author><category term="talks"/><category term="paper-presentation"/><summary type="html"><![CDATA[Presented by Avyav Singh]]></summary></entry><entry><title type="html">Generative Flow Networks (GFlowNets)</title><link href="https://kings-ai-rg.github.io/blog/2025/Generative-Flow-Networks/" rel="alternate" type="text/html" title="Generative Flow Networks (GFlowNets)"/><published>2025-02-14T12:00:00+00:00</published><updated>2025-02-14T12:00:00+00:00</updated><id>https://kings-ai-rg.github.io/blog/2025/Generative-Flow-Networks</id><content type="html" xml:base="https://kings-ai-rg.github.io/blog/2025/Generative-Flow-Networks/"><![CDATA[<p><strong><a href="https://www.linkedin.com/in/avyav-kumar-singh/">Avyav Singh</a></strong> presented the collection of papers that elucidate Generative Flow Networks (missing reference) (missing reference), (missing reference) and (missing reference).</p> <p><strong><em>Abstract</em></strong></p> <p>This talk explored the development of Generative Flow Networks (GFlowNets). We dissucssed how the use of amortized Bayesian inference to sample intractable posteriors, achieved through LLMs fine-tuning and diversity prioritised reinforcement learning algorithms enables data-efficient adaptation of LLMs.</p>]]></content><author><name></name></author><category term="talks"/><category term="paper-presentation"/><summary type="html"><![CDATA[Presented by Avyav Singh]]></summary></entry><entry><title type="html">NeurIPS 2024 Recap</title><link href="https://kings-ai-rg.github.io/blog/2025/neurips-recap/" rel="alternate" type="text/html" title="NeurIPS 2024 Recap"/><published>2025-01-17T12:00:00+00:00</published><updated>2025-01-17T12:00:00+00:00</updated><id>https://kings-ai-rg.github.io/blog/2025/neurips-recap</id><content type="html" xml:base="https://kings-ai-rg.github.io/blog/2025/neurips-recap/"><![CDATA[<p><strong><a href="https://www.linkedin.com/in/israelfmw/">Israel Mason-Williams</a></strong> and <strong><a href="https://www.linkedin.com/in/nathaliekirch/">Nathalie Kirch</a></strong> present on thier time at NeurIPS 2024.</p> <p><strong><em>Abstract</em></strong></p> <p>This meeting discussed talks and papers at NeurIPS 2024 that Israel and Nathalie saw that are of interest to the group. The papers covered were: ‘Generalization: Shortcuts, Spuriousness, and Stability’, ‘Universal Convergence’, ‘Initialization in GNNs’ and ‘Ablation Schemes for Interpretability’.</p>]]></content><author><name></name></author><category term="talks"/><category term="conference-update"/><summary type="html"><![CDATA[Presented by Israel Mason-Williams and Nathalie Kirch]]></summary></entry><entry><title type="html">Neural Network Compression - The Functional Perspective (+ Extensions)</title><link href="https://kings-ai-rg.github.io/blog/2024/functional-perspective/" rel="alternate" type="text/html" title="Neural Network Compression - The Functional Perspective (+ Extensions)"/><published>2024-11-08T12:00:00+00:00</published><updated>2024-11-08T12:00:00+00:00</updated><id>https://kings-ai-rg.github.io/blog/2024/functional-perspective</id><content type="html" xml:base="https://kings-ai-rg.github.io/blog/2024/functional-perspective/"><![CDATA[<p><strong><a href="https://openreview.net/profile?id=~Israel_Mason-Williams1">Israel Mason-Williams</a></strong> presented and discussed the paper Neural Network Compression: The Functional Perspective (+ Extensions) which was accepted at PML4LRS Workshop at ICLR 2024 <a class="citation" href="#mason-williams2024neural">(Mason-Williams, 2024)</a> and with extensions accepted at NeurIPS Sci4DL Workshop <a class="citation" href="#mason-williams2024knowledge">(Mason-Williams et al., 2024)</a>.</p> <p><strong><em>Abstract</em></strong></p> <p>Compression techniques, such as Knowledge distillation, Pruning, and Quantization reduce the computational costs of model inference and enable on-edge machine learning. The efficacy of compression methods is often evaluated through the proxy of accuracy and loss to understand similarity of the compressed model. This study aims to explore the functional divergence between compressed and uncompressed models. The results indicate that Quantization and Pruning create models that are functionally similar to the original model. In contrast, Knowledge distillation creates models that do not functionally approximate their teacher models. The compressed model resembles the dissimilarity of function observed in independently trained models. Therefore, it is verified, via a functional understanding, that Knowledge distillation is not a compression method. Thus, leading to the definition of Knowledge distillation as a training regulariser given that no knowledge is distilled from a teacher to a student.</p>]]></content><author><name></name></author><category term="talks"/><category term="published-paper"/><summary type="html"><![CDATA[Presented by Israel Mason-Williams]]></summary></entry></feed>